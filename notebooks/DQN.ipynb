{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import _pickle as cPickle\n",
    "from collections import namedtuple\n",
    "from gc import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "import traci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpu is to be used\n",
    "#device = torch.device('cpu')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, outputs, fc_2=False, fc_3=False):\n",
    "        super(DQN, self).__init__()\n",
    "        self.mlp1 = nn.Linear(6,32)\n",
    "        self.use_mlp2 = fc_2\n",
    "        self.use_mlp3 = fc_3\n",
    "        \n",
    "        if self.use_mlp2:\n",
    "            self.mlp2 = nn.Linear(32,64)\n",
    "            if self.use_mlp3:\n",
    "                self.mlp3 = nn.Linear(64,128)\n",
    "                self.head = nn.Linear(128, outputs)\n",
    "            else:\n",
    "                self.head = nn.Linear(64, outputs)\n",
    "        else:\n",
    "            self.head = nn.Linear(32, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        \n",
    "        if self.use_mlp2:\n",
    "            \n",
    "            x = F.relu(self.mlp2(x))\n",
    "            \n",
    "            if self.use_mlp3:\n",
    "                x = F.relu(self.mlp3(x))\n",
    "\n",
    "        return F.relu(self.head(x.view(x.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.001\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "n_actions = 5981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) *         math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state.view([-1,6]))\n",
    "    else:\n",
    "        return torch.randn(n_actions, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "\n",
    "    state_batch = torch.cat(batch.state).view(-1,6)\n",
    "    #action_batch = torch.cat(batch.action).view(-1,n_actions)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch)#.gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros((BATCH_SIZE, 5981), device=device)\n",
    "\n",
    "    nsv = target_net(non_final_next_states.view(-1,6)).detach()\n",
    "\n",
    "    next_state_values[nsv > 0] = nsv[nsv > 0]\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * GAMMA).t() + reward_batch).t()\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(num_episodes, date, exp_name, simconfig, layers):\n",
    "    #Main parameters\n",
    "    current_ep = 0\n",
    "    os.mkdir('./output_weights/policy/{}'.format(exp_name))\n",
    "    os.mkdir('./output_weights/target/{}'.format(exp_name))\n",
    "\n",
    "    if simconfig == 0:\n",
    "        sumoCmd = ['/usr/bin/sumo',\n",
    "             '-c',\n",
    "             '../sumo_simulation/sim_config/km2_centro/scenario/osm.sumocfg',\n",
    "             '-e', '86400']\n",
    "    else:\n",
    "        sumoCmd = [\"/usr/bin/sumo\", \"-c\", \n",
    "                   \"../sumo_simulation/sim_config/km2_centro/scenario_{}/osm.sumocfg\".format(simconfig),\n",
    "                  '-e', '86400']\n",
    "\n",
    "    action_dict = cPickle.load(open('../sumo_simulation/input/action_to_zone_km2_centro.pkl', 'rb'))\n",
    "    \n",
    "#     total_steps_1sim = 0\n",
    "    \n",
    "#     traci.start(sumoCmd)\n",
    "#     while traci.simulation.getMinExpectedNumber() > 0:\n",
    "#         traci.simulationStep()\n",
    "#         total_steps_1sim += 1\n",
    "#     traci.close(False)\n",
    "\n",
    "    with open('output/rewards_gamma001_experiment_{}_layers_{}'.format(date,layers), 'a') as reward_file:\n",
    "        for i_episode in range(num_episodes):\n",
    "            print(\"Episode {}\".format(i_episode))\n",
    "\n",
    "            state = np.zeros(6)\n",
    "            reward = 0\n",
    "            done = 0\n",
    "\n",
    "            #Start simulation\n",
    "            traci.start(sumoCmd)\n",
    "            id_list = traci.edge.getIDList()\n",
    "            lane_id_list = traci.lane.getIDList()\n",
    "\n",
    "            #Run simulation steps\n",
    "            traci_ep = 0\n",
    "            for w in range(86400):\n",
    "                if traci_ep >= 2*86400:\n",
    "                #if traci_ep >= 2 * total_steps_1sim:\n",
    "                    reward -= 800000\n",
    "                    break\n",
    "\n",
    "                if traci_ep % 3600 == 0 and traci_ep != 0:\n",
    "\n",
    "                    #Start agent interaction\n",
    "                    action = select_action(torch.tensor(state, device=device, dtype=torch.float))\n",
    "\n",
    "                    #Apply regulation and run steps\n",
    "                    reg_action = action > 0\n",
    "                    #lane_indices = (reg_action == 1).nonzero().view(-1)\n",
    "\n",
    "                    for index, lane_id in enumerate(reg_action.view(-1)):\n",
    "                    #for lane_id in lane_indices:\n",
    "                        if lane_id.item() == 1:\n",
    "                            if action_dict[index] is not None:\n",
    "                                traci.lane.setDisallowed(action_dict[index], ['truck'])\n",
    "                            else:\n",
    "                                reward -= 10000\n",
    "                        else:\n",
    "                            if action_dict[index] is not None:\n",
    "                                traci.lane.setAllowed(action_dict[index], ['truck'])\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "                    #Get simulation values\n",
    "                    co2 = [traci.lane.getCO2Emission(edge_id) for edge_id in lane_id_list]\n",
    "                    co = [traci.lane.getCOEmission(edge_id) for edge_id in lane_id_list]\n",
    "                    nox = [traci.lane.getNOxEmission(edge_id) for edge_id in lane_id_list]\n",
    "                    pmx = [traci.lane.getPMxEmission(edge_id) for edge_id in lane_id_list]\n",
    "                    noise = [traci.lane.getNoiseEmission(edge_id) for edge_id in lane_id_list]\n",
    "                    fuel = [traci.lane.getFuelConsumption(edge_id) for edge_id in lane_id_list]\n",
    "\n",
    "                    sim_results = np.array([co2, co, pmx, nox, noise, fuel])\n",
    "\n",
    "                    next_state = np.transpose(sim_results).mean(axis=0)\n",
    "\n",
    "                    vehicle_id_list = traci.vehicle.getIDList()\n",
    "                    vehicle_types = [traci.vehicle.getTypeID(v_id) for v_id in vehicle_id_list]\n",
    "                    vehicle_co2 = [traci.vehicle.getCO2Emission(v_id) for i, v_id in enumerate(vehicle_id_list)\n",
    "                                  if 'truck' in vehicle_types[i]]\n",
    "\n",
    "                    try:\n",
    "                        reward += (sum(vehicle_co2)/len(vehicle_co2)) * -1\n",
    "                    except:\n",
    "                        reward += 0\n",
    "\n",
    "                    #Convert to torch tensors\n",
    "                    reward = torch.tensor([reward], device=device, dtype=torch.float)\n",
    "                    state = torch.tensor(state, device=device, dtype=torch.float)\n",
    "                    next_state = torch.tensor(next_state, device=device, dtype=torch.float)\n",
    "\n",
    "                    print('Reward at timestep {t}: {r}'.format(t=traci_ep/3600,r=reward.item()))\n",
    "                    reward_file.write(','.join([str(i_episode), str(traci_ep/3600), str(reward.item())])+r'\\n')\n",
    "\n",
    "\n",
    "                    action = torch.tensor(action, device=device, dtype=torch.long).view(-1)\n",
    "                    action = (action == 1)#.nonzero().view(-1)\n",
    "\n",
    "                    if state.shape[0] == 0:\n",
    "                        memory.push(torch.zeros((1,12), device=device), action, next_state, reward)\n",
    "                    else:\n",
    "                        memory.push(state, action, next_state, reward)\n",
    "\n",
    "                    state += next_state\n",
    "                    # Perform one step of the optimization (on the target network)\n",
    "                    optimize_model()\n",
    "\n",
    "                traci.simulationStep()\n",
    "                traci_ep += 1\n",
    "\n",
    "            traci.close(False)\n",
    "\n",
    "             # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                 target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            torch.save(target_net.state_dict(), './output_weights/target/{}/target_net_weights_experiment_ep_{}.pt'.format(exp_name, i_episode))\n",
    "            torch.save(policy_net.state_dict(), './output_weights/policy/{}/policy_net_weights_experiment_ep_{}.pt'.format(exp_name, i_episode))\n",
    "        print('Complete')\n",
    "        torch.save(target_net.state_dict(), './output_weights/target/{}/target_net_weights_experiment_ep_{}.pt'.format(exp_name, i_episode))\n",
    "        torch.save(policy_net.state_dict(), './output_weights/policy/{}/policy_net_weights_experiment_ep_{}.pt'.format(exp_name, i_episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_net.to(device)\n",
    "# target_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16224020.0\n",
      "Reward at timestep 2.0: -32184020.0\n",
      "Reward at timestep 3.0: -48135424.0\n",
      "Reward at timestep 4.0: -63925424.0\n",
      "Reward at timestep 5.0: -80628608.0\n",
      "Reward at timestep 6.0: -96939840.0\n",
      "Reward at timestep 7.0: -112741072.0\n",
      "Reward at timestep 8.0: -128822328.0\n",
      "Reward at timestep 9.0: -145103712.0\n",
      "Reward at timestep 10.0: -161424544.0\n",
      "Reward at timestep 11.0: -177065680.0\n",
      "Reward at timestep 12.0: -192726912.0\n",
      "Reward at timestep 13.0: -208378192.0\n",
      "Reward at timestep 14.0: -223829504.0\n",
      "Reward at timestep 15.0: -239901008.0\n",
      "Reward at timestep 16.0: -256032288.0\n",
      "Reward at timestep 17.0: -271768320.0\n",
      "Reward at timestep 18.0: -287753984.0\n",
      "Reward at timestep 19.0: -303440224.0\n",
      "Reward at timestep 20.0: -319445856.0\n",
      "Reward at timestep 21.0: -335861088.0\n",
      "Reward at timestep 22.0: -352875168.0\n",
      "Reward at timestep 23.0: -368942176.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16354020.0\n",
      "Reward at timestep 2.0: -32535510.0\n",
      "Reward at timestep 3.0: -48516924.0\n",
      "Reward at timestep 4.0: -64528284.0\n",
      "Reward at timestep 5.0: -80329520.0\n",
      "Reward at timestep 6.0: -96280752.0\n",
      "Reward at timestep 7.0: -111911984.0\n",
      "Reward at timestep 8.0: -127723272.0\n",
      "Reward at timestep 9.0: -144024672.0\n",
      "Reward at timestep 10.0: -159805952.0\n",
      "Reward at timestep 11.0: -175906560.0\n",
      "Reward at timestep 12.0: -191607792.0\n",
      "Reward at timestep 13.0: -207279072.0\n",
      "Reward at timestep 14.0: -223190400.0\n",
      "Reward at timestep 15.0: -239251680.0\n",
      "Reward at timestep 16.0: -255832960.0\n",
      "Reward at timestep 17.0: -271928608.0\n",
      "Reward at timestep 18.0: -287614784.0\n",
      "Reward at timestep 19.0: -303820096.0\n",
      "Reward at timestep 20.0: -319865664.0\n",
      "Reward at timestep 21.0: -335991040.0\n",
      "Reward at timestep 22.0: -351627200.0\n",
      "Reward at timestep 23.0: -367722016.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -15994020.0\n",
      "Reward at timestep 2.0: -31845356.0\n",
      "Reward at timestep 3.0: -47726768.0\n",
      "Reward at timestep 4.0: -63647996.0\n",
      "Reward at timestep 5.0: -79779304.0\n",
      "Reward at timestep 6.0: -95500536.0\n",
      "Reward at timestep 7.0: -111521824.0\n",
      "Reward at timestep 8.0: -127773056.0\n",
      "Reward at timestep 9.0: -144124384.0\n",
      "Reward at timestep 10.0: -159775712.0\n",
      "Reward at timestep 11.0: -176047744.0\n",
      "Reward at timestep 12.0: -192448976.0\n",
      "Reward at timestep 13.0: -208150256.0\n",
      "Reward at timestep 14.0: -223841584.0\n",
      "Reward at timestep 15.0: -239542864.0\n",
      "Reward at timestep 16.0: -255234144.0\n",
      "Reward at timestep 17.0: -271121376.0\n",
      "Reward at timestep 18.0: -287157024.0\n",
      "Reward at timestep 19.0: -302094528.0\n",
      "Reward at timestep 20.0: -318189984.0\n",
      "Reward at timestep 21.0: -334345632.0\n",
      "Reward at timestep 22.0: -347146464.0\n",
      "Reward at timestep 23.0: -363042848.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16734020.0\n",
      "Reward at timestep 2.0: -28445510.0\n",
      "Reward at timestep 3.0: -44296840.0\n",
      "Reward at timestep 4.0: -60468200.0\n",
      "Reward at timestep 5.0: -76439520.0\n",
      "Reward at timestep 6.0: -84950752.0\n",
      "Reward at timestep 7.0: -101161744.0\n",
      "Reward at timestep 8.0: -117323072.0\n",
      "Reward at timestep 9.0: -133264488.0\n",
      "Reward at timestep 10.0: -139295760.0\n",
      "Reward at timestep 11.0: -154636368.0\n",
      "Reward at timestep 12.0: -170757600.0\n",
      "Reward at timestep 13.0: -186968880.0\n",
      "Reward at timestep 14.0: -203190144.0\n",
      "Reward at timestep 15.0: -218891376.0\n",
      "Reward at timestep 16.0: -235062656.0\n",
      "Reward at timestep 17.0: -251313904.0\n",
      "Reward at timestep 18.0: -267535184.0\n",
      "Reward at timestep 19.0: -269844352.0\n",
      "Reward at timestep 20.0: -286048992.0\n",
      "Reward at timestep 21.0: -302144448.0\n",
      "Reward at timestep 22.0: -303713248.0\n",
      "Reward at timestep 23.0: -319600096.0\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -15944020.0\n",
      "Reward at timestep 2.0: -18435308.0\n",
      "Reward at timestep 3.0: -19476206.0\n",
      "Reward at timestep 4.0: -20287696.0\n",
      "Reward at timestep 5.0: -20949130.0\n",
      "Reward at timestep 6.0: -36901016.0\n",
      "Reward at timestep 7.0: -37201016.0\n",
      "Reward at timestep 8.0: -53382800.0\n",
      "Reward at timestep 9.0: -69174208.0\n",
      "Reward at timestep 10.0: -85285464.0\n",
      "Reward at timestep 11.0: -85385464.0\n",
      "Reward at timestep 12.0: -101596624.0\n",
      "Reward at timestep 13.0: -101657912.0\n",
      "Reward at timestep 14.0: -101700672.0\n",
      "Reward at timestep 15.0: -101723824.0\n",
      "Reward at timestep 16.0: -101733824.0\n",
      "Reward at timestep 17.0: -101748728.0\n",
      "Reward at timestep 18.0: -101761320.0\n",
      "Reward at timestep 19.0: -101771320.0\n",
      "Reward at timestep 20.0: -101781320.0\n",
      "Reward at timestep 21.0: -101791320.0\n",
      "Reward at timestep 22.0: -118193248.0\n",
      "Reward at timestep 23.0: -134225984.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11494020.0\n",
      "Reward at timestep 2.0: -28135308.0\n",
      "Reward at timestep 3.0: -44216720.0\n",
      "Reward at timestep 4.0: -44218080.0\n",
      "Reward at timestep 5.0: -44218080.0\n",
      "Reward at timestep 6.0: -44221652.0\n",
      "Reward at timestep 7.0: -60476584.0\n",
      "Reward at timestep 8.0: -76357872.0\n",
      "Reward at timestep 9.0: -76359288.0\n",
      "Reward at timestep 10.0: -92414936.0\n",
      "Reward at timestep 11.0: -92417296.0\n",
      "Reward at timestep 12.0: -108279208.0\n",
      "Reward at timestep 13.0: -124029208.0\n",
      "Reward at timestep 14.0: -124030464.0\n",
      "Reward at timestep 15.0: -140334352.0\n",
      "Reward at timestep 16.0: -156585632.0\n",
      "Reward at timestep 17.0: -172786880.0\n",
      "Reward at timestep 18.0: -172788160.0\n",
      "Reward at timestep 19.0: -189150544.0\n",
      "Reward at timestep 20.0: -189151808.0\n",
      "Reward at timestep 21.0: -189152960.0\n",
      "Reward at timestep 22.0: -189152960.0\n",
      "Reward at timestep 23.0: -189153968.0\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11364020.0\n",
      "Reward at timestep 2.0: -27565308.0\n",
      "Reward at timestep 3.0: -27596722.0\n",
      "Reward at timestep 4.0: -43866720.0\n",
      "Reward at timestep 5.0: -60066720.0\n",
      "Reward at timestep 6.0: -60067948.0\n",
      "Reward at timestep 7.0: -60071736.0\n",
      "Reward at timestep 8.0: -76344736.0\n",
      "Reward at timestep 9.0: -92404736.0\n",
      "Reward at timestep 10.0: -108235968.0\n",
      "Reward at timestep 11.0: -124136784.0\n",
      "Reward at timestep 12.0: -139906784.0\n",
      "Reward at timestep 13.0: -155988048.0\n",
      "Reward at timestep 14.0: -171838048.0\n",
      "Reward at timestep 15.0: -171839312.0\n",
      "Reward at timestep 16.0: -188189312.0\n",
      "Reward at timestep 17.0: -188190576.0\n",
      "Reward at timestep 18.0: -204354064.0\n",
      "Reward at timestep 19.0: -204355472.0\n",
      "Reward at timestep 20.0: -204355472.0\n",
      "Reward at timestep 21.0: -204356640.0\n",
      "Reward at timestep 22.0: -204356640.0\n",
      "Reward at timestep 23.0: -220366640.0\n",
      "Episode 7\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11364020.0\n",
      "Reward at timestep 2.0: -27745308.0\n",
      "Reward at timestep 3.0: -27746712.0\n",
      "Reward at timestep 4.0: -27746712.0\n",
      "Reward at timestep 5.0: -43650664.0\n",
      "Reward at timestep 6.0: -43651892.0\n",
      "Reward at timestep 7.0: -60136848.0\n",
      "Reward at timestep 8.0: -60138120.0\n",
      "Reward at timestep 9.0: -60138120.0\n",
      "Reward at timestep 10.0: -60143272.0\n",
      "Reward at timestep 11.0: -60144456.0\n",
      "Reward at timestep 12.0: -60147564.0\n",
      "Reward at timestep 13.0: -76097568.0\n",
      "Reward at timestep 14.0: -76098800.0\n",
      "Reward at timestep 15.0: -92361776.0\n",
      "Reward at timestep 16.0: -92363064.0\n",
      "Reward at timestep 17.0: -92366288.0\n",
      "Reward at timestep 18.0: -92366288.0\n",
      "Reward at timestep 19.0: -108726288.0\n",
      "Reward at timestep 20.0: -108727544.0\n",
      "Reward at timestep 21.0: -108728520.0\n",
      "Reward at timestep 22.0: -125208520.0\n",
      "Reward at timestep 23.0: -125210536.0\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11374020.0\n",
      "Reward at timestep 2.0: -11385308.0\n",
      "Reward at timestep 3.0: -27566816.0\n",
      "Reward at timestep 4.0: -27568144.0\n",
      "Reward at timestep 5.0: -44004080.0\n",
      "Reward at timestep 6.0: -44005308.0\n",
      "Reward at timestep 7.0: -44008572.0\n",
      "Reward at timestep 8.0: -59901432.0\n",
      "Reward at timestep 9.0: -75702840.0\n",
      "Reward at timestep 10.0: -91964128.0\n",
      "Reward at timestep 11.0: -91967784.0\n",
      "Reward at timestep 12.0: -91967784.0\n",
      "Reward at timestep 13.0: -108331152.0\n",
      "Reward at timestep 14.0: -108332416.0\n",
      "Reward at timestep 15.0: -108332416.0\n",
      "Reward at timestep 16.0: -124362416.0\n",
      "Reward at timestep 17.0: -124363672.0\n",
      "Reward at timestep 18.0: -124367432.0\n",
      "Reward at timestep 19.0: -124369608.0\n",
      "Reward at timestep 20.0: -140729616.0\n",
      "Reward at timestep 21.0: -156830848.0\n",
      "Reward at timestep 22.0: -173321456.0\n",
      "Reward at timestep 23.0: -173323296.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16564020.0\n",
      "Reward at timestep 2.0: -16575400.0\n",
      "Reward at timestep 3.0: -32519884.0\n",
      "Reward at timestep 4.0: -48791200.0\n",
      "Reward at timestep 5.0: -48792428.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 6.0: -48792428.0\n",
      "Reward at timestep 7.0: -64757536.0\n",
      "Reward at timestep 8.0: -80968392.0\n",
      "Reward at timestep 9.0: -80969760.0\n",
      "Reward at timestep 10.0: -80984328.0\n",
      "Reward at timestep 11.0: -80987496.0\n",
      "Reward at timestep 12.0: -80988728.0\n",
      "Reward at timestep 13.0: -80991248.0\n",
      "Reward at timestep 14.0: -80991248.0\n",
      "Reward at timestep 15.0: -96501248.0\n",
      "Reward at timestep 16.0: -96501248.0\n",
      "Reward at timestep 17.0: -96505696.0\n",
      "Reward at timestep 18.0: -96508336.0\n",
      "Reward at timestep 19.0: -112618336.0\n",
      "Reward at timestep 20.0: -128579592.0\n",
      "Reward at timestep 21.0: -144730816.0\n",
      "Reward at timestep 22.0: -144732128.0\n",
      "Reward at timestep 23.0: -144733248.0\n",
      "Complete\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11370000.0\n",
      "Reward at timestep 2.0: -14351001.0\n",
      "Reward at timestep 3.0: -14352172.0\n",
      "Reward at timestep 4.0: -14353386.0\n",
      "Reward at timestep 5.0: -30066664.0\n",
      "Reward at timestep 6.0: -30067936.0\n",
      "Reward at timestep 7.0: -30069162.0\n",
      "Reward at timestep 8.0: -30072000.0\n",
      "Reward at timestep 9.0: -46032000.0\n",
      "Reward at timestep 10.0: -46033268.0\n",
      "Reward at timestep 11.0: -46036040.0\n",
      "Reward at timestep 12.0: -62279036.0\n",
      "Reward at timestep 13.0: -62280932.0\n",
      "Reward at timestep 14.0: -62283044.0\n",
      "Reward at timestep 15.0: -62284576.0\n",
      "Reward at timestep 16.0: -62288372.0\n",
      "Reward at timestep 17.0: -62290872.0\n",
      "Reward at timestep 18.0: -62293344.0\n",
      "Reward at timestep 19.0: -77944232.0\n",
      "Reward at timestep 20.0: -77945520.0\n",
      "Reward at timestep 21.0: -77946280.0\n",
      "Reward at timestep 22.0: -93548544.0\n",
      "Reward at timestep 23.0: -109460264.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11130000.0\n",
      "Reward at timestep 2.0: -12211001.0\n",
      "Reward at timestep 3.0: -12212550.0\n",
      "Reward at timestep 4.0: -12216501.0\n",
      "Reward at timestep 5.0: -12217815.0\n",
      "Reward at timestep 6.0: -12219962.0\n",
      "Reward at timestep 7.0: -12219962.0\n",
      "Reward at timestep 8.0: -28192268.0\n",
      "Reward at timestep 9.0: -45143528.0\n",
      "Reward at timestep 10.0: -45144144.0\n",
      "Reward at timestep 11.0: -60984976.0\n",
      "Reward at timestep 12.0: -60986204.0\n",
      "Reward at timestep 13.0: -60987100.0\n",
      "Reward at timestep 14.0: -77019664.0\n",
      "Reward at timestep 15.0: -93171040.0\n",
      "Reward at timestep 16.0: -109682328.0\n",
      "Reward at timestep 17.0: -125623632.0\n",
      "Reward at timestep 18.0: -125624864.0\n",
      "Reward at timestep 19.0: -125627032.0\n",
      "Reward at timestep 20.0: -125628768.0\n",
      "Reward at timestep 21.0: -125631440.0\n",
      "Reward at timestep 22.0: -141793232.0\n",
      "Reward at timestep 23.0: -141794816.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11050000.0\n",
      "Reward at timestep 2.0: -11741001.0\n",
      "Reward at timestep 3.0: -11743044.0\n",
      "Reward at timestep 4.0: -11743044.0\n",
      "Reward at timestep 5.0: -11745900.0\n",
      "Reward at timestep 6.0: -11747398.0\n",
      "Reward at timestep 7.0: -11748577.0\n",
      "Reward at timestep 8.0: -28290672.0\n",
      "Reward at timestep 9.0: -28291930.0\n",
      "Reward at timestep 10.0: -28294616.0\n",
      "Reward at timestep 11.0: -28296964.0\n",
      "Reward at timestep 12.0: -28298472.0\n",
      "Reward at timestep 13.0: -44779224.0\n",
      "Reward at timestep 14.0: -44780472.0\n",
      "Reward at timestep 15.0: -60910472.0\n",
      "Reward at timestep 16.0: -60911760.0\n",
      "Reward at timestep 17.0: -60916072.0\n",
      "Reward at timestep 18.0: -60916072.0\n",
      "Reward at timestep 19.0: -60916568.0\n",
      "Reward at timestep 20.0: -60917656.0\n",
      "Reward at timestep 21.0: -60917656.0\n",
      "Reward at timestep 22.0: -60919896.0\n",
      "Reward at timestep 23.0: -60921596.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -11030000.0\n",
      "Reward at timestep 2.0: -11401001.0\n",
      "Reward at timestep 3.0: -11402366.0\n",
      "Reward at timestep 4.0: -11402366.0\n",
      "Reward at timestep 5.0: -11402366.0\n",
      "Reward at timestep 6.0: -11402366.0\n",
      "Reward at timestep 7.0: -11405467.0\n",
      "Reward at timestep 8.0: -11408072.0\n",
      "Reward at timestep 9.0: -11408072.0\n",
      "Reward at timestep 10.0: -11410043.0\n",
      "Reward at timestep 11.0: -27922278.0\n",
      "Reward at timestep 12.0: -27923506.0\n",
      "Reward at timestep 13.0: -43916168.0\n",
      "Reward at timestep 14.0: -43918524.0\n",
      "Reward at timestep 15.0: -43919708.0\n",
      "Reward at timestep 16.0: -59853524.0\n",
      "Reward at timestep 17.0: -59854832.0\n",
      "Reward at timestep 18.0: -59857560.0\n",
      "Reward at timestep 19.0: -59857560.0\n",
      "Reward at timestep 20.0: -75948760.0\n",
      "Reward at timestep 21.0: -75950048.0\n",
      "Reward at timestep 22.0: -92150744.0\n",
      "Reward at timestep 23.0: -92152632.0\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10950000.0\n",
      "Reward at timestep 2.0: -11181001.0\n",
      "Reward at timestep 3.0: -11182797.0\n",
      "Reward at timestep 4.0: -11185512.0\n",
      "Reward at timestep 5.0: -11190271.0\n",
      "Reward at timestep 6.0: -11191298.0\n",
      "Reward at timestep 7.0: -11193834.0\n",
      "Reward at timestep 8.0: -26916038.0\n",
      "Reward at timestep 9.0: -26917286.0\n",
      "Reward at timestep 10.0: -43017988.0\n",
      "Reward at timestep 11.0: -59499260.0\n",
      "Reward at timestep 12.0: -59500576.0\n",
      "Reward at timestep 13.0: -59502464.0\n",
      "Reward at timestep 14.0: -59502464.0\n",
      "Reward at timestep 15.0: -75485416.0\n",
      "Reward at timestep 16.0: -91566736.0\n",
      "Reward at timestep 17.0: -108338048.0\n",
      "Reward at timestep 18.0: -108339312.0\n",
      "Reward at timestep 19.0: -108340328.0\n",
      "Reward at timestep 20.0: -108341888.0\n",
      "Reward at timestep 21.0: -108343880.0\n",
      "Reward at timestep 22.0: -124405672.0\n",
      "Reward at timestep 23.0: -140506928.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10860000.0\n",
      "Reward at timestep 2.0: -10981213.0\n",
      "Reward at timestep 3.0: -27113326.0\n",
      "Reward at timestep 4.0: -43194632.0\n",
      "Reward at timestep 5.0: -43195944.0\n",
      "Reward at timestep 6.0: -43199600.0\n",
      "Reward at timestep 7.0: -43201000.0\n",
      "Reward at timestep 8.0: -59683448.0\n",
      "Reward at timestep 9.0: -59684784.0\n",
      "Reward at timestep 10.0: -59685676.0\n",
      "Reward at timestep 11.0: -59688648.0\n",
      "Reward at timestep 12.0: -59691560.0\n",
      "Reward at timestep 13.0: -75473192.0\n",
      "Reward at timestep 14.0: -91465400.0\n",
      "Reward at timestep 15.0: -91466656.0\n",
      "Reward at timestep 16.0: -107770672.0\n",
      "Reward at timestep 17.0: -124141984.0\n",
      "Reward at timestep 18.0: -124143272.0\n",
      "Reward at timestep 19.0: -124146048.0\n",
      "Reward at timestep 20.0: -124148840.0\n",
      "Reward at timestep 21.0: -140119760.0\n",
      "Reward at timestep 22.0: -140121088.0\n",
      "Reward at timestep 23.0: -156283600.0\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16100000.0\n",
      "Reward at timestep 2.0: -16141258.0\n",
      "Reward at timestep 3.0: -16142534.0\n",
      "Reward at timestep 4.0: -16145900.0\n",
      "Reward at timestep 5.0: -16148119.0\n",
      "Reward at timestep 6.0: -16151390.0\n",
      "Reward at timestep 7.0: -16152836.0\n",
      "Reward at timestep 8.0: -16154136.0\n",
      "Reward at timestep 9.0: -16155311.0\n",
      "Reward at timestep 10.0: -32465918.0\n",
      "Reward at timestep 11.0: -32467250.0\n",
      "Reward at timestep 12.0: -32468332.0\n",
      "Reward at timestep 13.0: -32470996.0\n",
      "Reward at timestep 14.0: -32474430.0\n",
      "Reward at timestep 15.0: -32475452.0\n",
      "Reward at timestep 16.0: -32475452.0\n",
      "Reward at timestep 17.0: -32478338.0\n",
      "Reward at timestep 18.0: -32479614.0\n",
      "Reward at timestep 19.0: -32480278.0\n",
      "Reward at timestep 20.0: -32481460.0\n",
      "Reward at timestep 21.0: -32483454.0\n",
      "Reward at timestep 22.0: -32484320.0\n",
      "Reward at timestep 23.0: -32486170.0\n",
      "Episode 7\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10790000.0\n",
      "Reward at timestep 2.0: -10801270.0\n",
      "Reward at timestep 3.0: -10802676.0\n",
      "Reward at timestep 4.0: -26543944.0\n",
      "Reward at timestep 5.0: -26545286.0\n",
      "Reward at timestep 6.0: -26545286.0\n",
      "Reward at timestep 7.0: -26548040.0\n",
      "Reward at timestep 8.0: -26550192.0\n",
      "Reward at timestep 9.0: -26550192.0\n",
      "Reward at timestep 10.0: -26552856.0\n",
      "Reward at timestep 11.0: -26553762.0\n",
      "Reward at timestep 12.0: -26556734.0\n",
      "Reward at timestep 13.0: -26558886.0\n",
      "Reward at timestep 14.0: -26560574.0\n",
      "Reward at timestep 15.0: -26561590.0\n",
      "Reward at timestep 16.0: -26564348.0\n",
      "Reward at timestep 17.0: -42638508.0\n",
      "Reward at timestep 18.0: -42639776.0\n",
      "Reward at timestep 19.0: -42640576.0\n",
      "Reward at timestep 20.0: -42641824.0\n",
      "Reward at timestep 21.0: -42643772.0\n",
      "Reward at timestep 22.0: -42644748.0\n",
      "Reward at timestep 23.0: -42646572.0\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10790000.0\n",
      "Reward at timestep 2.0: -10801270.0\n",
      "Reward at timestep 3.0: -10802676.0\n",
      "Reward at timestep 4.0: -10803945.0\n",
      "Reward at timestep 5.0: -10806912.0\n",
      "Reward at timestep 6.0: -10806912.0\n",
      "Reward at timestep 7.0: -27048300.0\n",
      "Reward at timestep 8.0: -27049600.0\n",
      "Reward at timestep 9.0: -27052706.0\n",
      "Reward at timestep 10.0: -43373744.0\n",
      "Reward at timestep 11.0: -43375452.0\n",
      "Reward at timestep 12.0: -43378436.0\n",
      "Reward at timestep 13.0: -43379264.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 14.0: -43379264.0\n",
      "Reward at timestep 15.0: -43379264.0\n",
      "Reward at timestep 16.0: -43379264.0\n",
      "Reward at timestep 17.0: -43382456.0\n",
      "Reward at timestep 18.0: -43385156.0\n",
      "Reward at timestep 19.0: -43385964.0\n",
      "Reward at timestep 20.0: -43387116.0\n",
      "Reward at timestep 21.0: -43388684.0\n",
      "Reward at timestep 22.0: -43390808.0\n",
      "Reward at timestep 23.0: -43393640.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10780000.0\n",
      "Reward at timestep 2.0: -27061270.0\n",
      "Reward at timestep 3.0: -27062528.0\n",
      "Reward at timestep 4.0: -27066130.0\n",
      "Reward at timestep 5.0: -27066130.0\n",
      "Reward at timestep 6.0: -27066130.0\n",
      "Reward at timestep 7.0: -27067592.0\n",
      "Reward at timestep 8.0: -27068646.0\n",
      "Reward at timestep 9.0: -27068646.0\n",
      "Reward at timestep 10.0: -27071484.0\n",
      "Reward at timestep 11.0: -27074156.0\n",
      "Reward at timestep 12.0: -27074156.0\n",
      "Reward at timestep 13.0: -27076638.0\n",
      "Reward at timestep 14.0: -27078562.0\n",
      "Reward at timestep 15.0: -27079988.0\n",
      "Reward at timestep 16.0: -27082956.0\n",
      "Reward at timestep 17.0: -27085690.0\n",
      "Reward at timestep 18.0: -27085690.0\n",
      "Reward at timestep 19.0: -27087558.0\n",
      "Reward at timestep 20.0: -43219028.0\n",
      "Reward at timestep 21.0: -43220296.0\n",
      "Reward at timestep 22.0: -43221172.0\n",
      "Reward at timestep 23.0: -43222720.0\n",
      "Complete\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -10795280.0\n",
      "Reward at timestep 9.0: -10796529.0\n",
      "Reward at timestep 10.0: -10800270.0\n",
      "Reward at timestep 11.0: -10800994.0\n",
      "Reward at timestep 12.0: -27391530.0\n",
      "Reward at timestep 13.0: -27392818.0\n",
      "Reward at timestep 14.0: -27394110.0\n",
      "Reward at timestep 15.0: -27396826.0\n",
      "Reward at timestep 16.0: -27399790.0\n",
      "Reward at timestep 17.0: -27402992.0\n",
      "Reward at timestep 18.0: -27405448.0\n",
      "Reward at timestep 19.0: -27406930.0\n",
      "Reward at timestep 20.0: -43839412.0\n",
      "Reward at timestep 21.0: -43840740.0\n",
      "Reward at timestep 22.0: -59682040.0\n",
      "Reward at timestep 23.0: -76233200.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -26531364.0\n",
      "Reward at timestep 7.0: -26532752.0\n",
      "Reward at timestep 8.0: -26535132.0\n",
      "Reward at timestep 9.0: -26535132.0\n",
      "Reward at timestep 10.0: -26537300.0\n",
      "Reward at timestep 11.0: -26538338.0\n",
      "Reward at timestep 12.0: -26540062.0\n",
      "Reward at timestep 13.0: -26542098.0\n",
      "Reward at timestep 14.0: -26544246.0\n",
      "Reward at timestep 15.0: -26545208.0\n",
      "Reward at timestep 16.0: -26546898.0\n",
      "Reward at timestep 17.0: -26549836.0\n",
      "Reward at timestep 18.0: -42382444.0\n",
      "Reward at timestep 19.0: -42383864.0\n",
      "Reward at timestep 20.0: -42386560.0\n",
      "Reward at timestep 21.0: -42388240.0\n",
      "Reward at timestep 22.0: -42388992.0\n",
      "Reward at timestep 23.0: -42392248.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -10795280.0\n",
      "Reward at timestep 9.0: -10796529.0\n",
      "Reward at timestep 10.0: -27250268.0\n",
      "Reward at timestep 11.0: -27251402.0\n",
      "Reward at timestep 12.0: -43583260.0\n",
      "Reward at timestep 13.0: -43584548.0\n",
      "Reward at timestep 14.0: -43585652.0\n",
      "Reward at timestep 15.0: -43587328.0\n",
      "Reward at timestep 16.0: -43588892.0\n",
      "Reward at timestep 17.0: -43590104.0\n",
      "Reward at timestep 18.0: -43592400.0\n",
      "Reward at timestep 19.0: -43594528.0\n",
      "Reward at timestep 20.0: -43596276.0\n",
      "Reward at timestep 21.0: -43599920.0\n",
      "Reward at timestep 22.0: -43601680.0\n",
      "Reward at timestep 23.0: -43604160.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -26434156.0\n",
      "Reward at timestep 3.0: -26435612.0\n",
      "Reward at timestep 4.0: -26437158.0\n",
      "Reward at timestep 5.0: -42219584.0\n",
      "Reward at timestep 6.0: -42220904.0\n",
      "Reward at timestep 7.0: -42222028.0\n",
      "Reward at timestep 8.0: -58222028.0\n",
      "Reward at timestep 9.0: -58223308.0\n",
      "Reward at timestep 10.0: -58225244.0\n",
      "Reward at timestep 11.0: -58226816.0\n",
      "Reward at timestep 12.0: -58229184.0\n",
      "Reward at timestep 13.0: -58231720.0\n",
      "Reward at timestep 14.0: -74323640.0\n",
      "Reward at timestep 15.0: -90774920.0\n",
      "Reward at timestep 16.0: -90776224.0\n",
      "Reward at timestep 17.0: -90777656.0\n",
      "Reward at timestep 18.0: -90780536.0\n",
      "Reward at timestep 19.0: -90782024.0\n",
      "Reward at timestep 20.0: -90784472.0\n",
      "Reward at timestep 21.0: -90785568.0\n",
      "Reward at timestep 22.0: -90787728.0\n",
      "Reward at timestep 23.0: -90789192.0\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -26996366.0\n",
      "Reward at timestep 4.0: -26997696.0\n",
      "Reward at timestep 5.0: -26999580.0\n",
      "Reward at timestep 6.0: -27001388.0\n",
      "Reward at timestep 7.0: -27002528.0\n",
      "Reward at timestep 8.0: -27005154.0\n",
      "Reward at timestep 9.0: -43736828.0\n",
      "Reward at timestep 10.0: -43737880.0\n",
      "Reward at timestep 11.0: -43740140.0\n",
      "Reward at timestep 12.0: -43743296.0\n",
      "Reward at timestep 13.0: -43745956.0\n",
      "Reward at timestep 14.0: -43746700.0\n",
      "Reward at timestep 15.0: -43748400.0\n",
      "Reward at timestep 16.0: -43750976.0\n",
      "Reward at timestep 17.0: -43751632.0\n",
      "Reward at timestep 18.0: -43753424.0\n",
      "Reward at timestep 19.0: -43754596.0\n",
      "Reward at timestep 20.0: -43755332.0\n",
      "Reward at timestep 21.0: -43756072.0\n",
      "Reward at timestep 22.0: -43757140.0\n",
      "Reward at timestep 23.0: -43760820.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16082876.0\n",
      "Reward at timestep 2.0: -16084450.0\n",
      "Reward at timestep 3.0: -31855930.0\n",
      "Reward at timestep 4.0: -31857228.0\n",
      "Reward at timestep 5.0: -31859640.0\n",
      "Reward at timestep 6.0: -31860042.0\n",
      "Reward at timestep 7.0: -31861304.0\n",
      "Reward at timestep 8.0: -31862674.0\n",
      "Reward at timestep 9.0: -31864144.0\n",
      "Reward at timestep 10.0: -31866056.0\n",
      "Reward at timestep 11.0: -31868524.0\n",
      "Reward at timestep 12.0: -48020796.0\n",
      "Reward at timestep 13.0: -48021900.0\n",
      "Reward at timestep 14.0: -48023472.0\n",
      "Reward at timestep 15.0: -48025532.0\n",
      "Reward at timestep 16.0: -48027524.0\n",
      "Reward at timestep 17.0: -48029244.0\n",
      "Reward at timestep 18.0: -48030844.0\n",
      "Reward at timestep 19.0: -48033312.0\n",
      "Reward at timestep 20.0: -48034668.0\n",
      "Reward at timestep 21.0: -48036284.0\n",
      "Reward at timestep 22.0: -48037908.0\n",
      "Reward at timestep 23.0: -48039676.0\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -10795280.0\n",
      "Reward at timestep 9.0: -10796529.0\n",
      "Reward at timestep 10.0: -10800270.0\n",
      "Reward at timestep 11.0: -10800994.0\n",
      "Reward at timestep 12.0: -10803674.0\n",
      "Reward at timestep 13.0: -10806328.0\n",
      "Reward at timestep 14.0: -10808963.0\n",
      "Reward at timestep 15.0: -10809643.0\n",
      "Reward at timestep 16.0: -10812153.0\n",
      "Reward at timestep 17.0: -10814499.0\n",
      "Reward at timestep 18.0: -10816895.0\n",
      "Reward at timestep 19.0: -10828265.0\n",
      "Reward at timestep 20.0: -10839648.0\n",
      "Reward at timestep 21.0: -10851361.0\n",
      "Reward at timestep 22.0: -10852912.0\n",
      "Reward at timestep 23.0: -27165004.0\n",
      "Episode 7\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -10795280.0\n",
      "Reward at timestep 9.0: -10796529.0\n",
      "Reward at timestep 10.0: -10800270.0\n",
      "Reward at timestep 11.0: -10800994.0\n",
      "Reward at timestep 12.0: -10803674.0\n",
      "Reward at timestep 13.0: -10806328.0\n",
      "Reward at timestep 14.0: -10808963.0\n",
      "Reward at timestep 15.0: -10809643.0\n",
      "Reward at timestep 16.0: -10812153.0\n",
      "Reward at timestep 17.0: -10814499.0\n",
      "Reward at timestep 18.0: -10816895.0\n",
      "Reward at timestep 19.0: -10818265.0\n",
      "Reward at timestep 20.0: -10819648.0\n",
      "Reward at timestep 21.0: -10821361.0\n",
      "Reward at timestep 22.0: -10822912.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 23.0: -10825004.0\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -10795280.0\n",
      "Reward at timestep 9.0: -10796529.0\n",
      "Reward at timestep 10.0: -10800270.0\n",
      "Reward at timestep 11.0: -10800994.0\n",
      "Reward at timestep 12.0: -10803674.0\n",
      "Reward at timestep 13.0: -27276328.0\n",
      "Reward at timestep 14.0: -43377644.0\n",
      "Reward at timestep 15.0: -59358920.0\n",
      "Reward at timestep 16.0: -75450216.0\n",
      "Reward at timestep 17.0: -75451536.0\n",
      "Reward at timestep 18.0: -75453624.0\n",
      "Reward at timestep 19.0: -75455000.0\n",
      "Reward at timestep 20.0: -75456928.0\n",
      "Reward at timestep 21.0: -75456928.0\n",
      "Reward at timestep 22.0: -75458712.0\n",
      "Reward at timestep 23.0: -75460112.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -10782876.0\n",
      "Reward at timestep 2.0: -10784155.0\n",
      "Reward at timestep 3.0: -10786364.0\n",
      "Reward at timestep 4.0: -10788647.0\n",
      "Reward at timestep 5.0: -10791365.0\n",
      "Reward at timestep 6.0: -10791365.0\n",
      "Reward at timestep 7.0: -10792723.0\n",
      "Reward at timestep 8.0: -26675280.0\n",
      "Reward at timestep 9.0: -26676538.0\n",
      "Reward at timestep 10.0: -26677058.0\n",
      "Reward at timestep 11.0: -26679352.0\n",
      "Reward at timestep 12.0: -26681598.0\n",
      "Reward at timestep 13.0: -26683434.0\n",
      "Reward at timestep 14.0: -26685504.0\n",
      "Reward at timestep 15.0: -26688306.0\n",
      "Reward at timestep 16.0: -26689174.0\n",
      "Reward at timestep 17.0: -26691692.0\n",
      "Reward at timestep 18.0: -26694914.0\n",
      "Reward at timestep 19.0: -26696754.0\n",
      "Reward at timestep 20.0: -42717964.0\n",
      "Reward at timestep 21.0: -42719124.0\n",
      "Reward at timestep 22.0: -42719124.0\n",
      "Reward at timestep 23.0: -42721736.0\n",
      "Complete\n",
      "Using 1 GPU\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -15924020.0\n",
      "Reward at timestep 2.0: -31585510.0\n",
      "Reward at timestep 3.0: -47256916.0\n",
      "Reward at timestep 4.0: -63038144.0\n",
      "Reward at timestep 5.0: -78749464.0\n",
      "Reward at timestep 6.0: -94560696.0\n",
      "Reward at timestep 7.0: -110421928.0\n",
      "Reward at timestep 8.0: -126283216.0\n",
      "Reward at timestep 9.0: -142374560.0\n",
      "Reward at timestep 10.0: -158245808.0\n",
      "Reward at timestep 11.0: -174147152.0\n",
      "Reward at timestep 12.0: -190058384.0\n",
      "Reward at timestep 13.0: -205969664.0\n",
      "Reward at timestep 14.0: -221830896.0\n",
      "Reward at timestep 15.0: -237692160.0\n",
      "Reward at timestep 16.0: -253553440.0\n",
      "Reward at timestep 17.0: -269421888.0\n",
      "Reward at timestep 18.0: -285287744.0\n",
      "Reward at timestep 19.0: -301123712.0\n",
      "Reward at timestep 20.0: -316969536.0\n",
      "Reward at timestep 21.0: -332834112.0\n",
      "Reward at timestep 22.0: -348720064.0\n",
      "Reward at timestep 23.0: -364605440.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -15924020.0\n",
      "Reward at timestep 2.0: -31585510.0\n",
      "Reward at timestep 3.0: -47256916.0\n",
      "Reward at timestep 4.0: -63038144.0\n",
      "Reward at timestep 5.0: -78749464.0\n",
      "Reward at timestep 6.0: -94560696.0\n",
      "Reward at timestep 7.0: -110421928.0\n",
      "Reward at timestep 8.0: -126283216.0\n",
      "Reward at timestep 9.0: -142114560.0\n",
      "Reward at timestep 10.0: -157985792.0\n",
      "Reward at timestep 11.0: -173886208.0\n",
      "Reward at timestep 12.0: -189987440.0\n",
      "Reward at timestep 13.0: -205888720.0\n",
      "Reward at timestep 14.0: -221789952.0\n",
      "Reward at timestep 15.0: -237691216.0\n",
      "Reward at timestep 16.0: -253572496.0\n",
      "Reward at timestep 17.0: -269430912.0\n",
      "Reward at timestep 18.0: -285286784.0\n",
      "Reward at timestep 19.0: -301152704.0\n",
      "Reward at timestep 20.0: -316988544.0\n",
      "Reward at timestep 21.0: -332833152.0\n",
      "Reward at timestep 22.0: -348699136.0\n",
      "Reward at timestep 23.0: -364586048.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -15924020.0\n",
      "Reward at timestep 2.0: -32135510.0\n",
      "Reward at timestep 3.0: -47806916.0\n",
      "Reward at timestep 4.0: -63608144.0\n",
      "Reward at timestep 5.0: -79319464.0\n",
      "Reward at timestep 6.0: -95140080.0\n",
      "Reward at timestep 7.0: -111781312.0\n",
      "Reward at timestep 8.0: -127632280.0\n",
      "Reward at timestep 9.0: -143573616.0\n",
      "Reward at timestep 10.0: -159474848.0\n",
      "Reward at timestep 11.0: -175376096.0\n",
      "Reward at timestep 12.0: -191287328.0\n",
      "Reward at timestep 13.0: -207208608.0\n",
      "Reward at timestep 14.0: -223109840.0\n",
      "Reward at timestep 15.0: -239031104.0\n",
      "Reward at timestep 16.0: -254942384.0\n",
      "Reward at timestep 17.0: -270828544.0\n",
      "Reward at timestep 18.0: -286694400.0\n",
      "Reward at timestep 19.0: -301242432.0\n",
      "Reward at timestep 20.0: -314491200.0\n",
      "Reward at timestep 21.0: -326472000.0\n",
      "Reward at timestep 22.0: -337184832.0\n",
      "Reward at timestep 23.0: -346512640.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -13404020.0\n",
      "Reward at timestep 2.0: -23205380.0\n",
      "Reward at timestep 3.0: -31036794.0\n",
      "Reward at timestep 4.0: -36998068.0\n",
      "Reward at timestep 5.0: -41739688.0\n",
      "Reward at timestep 6.0: -45660508.0\n",
      "Reward at timestep 7.0: -49114284.0\n",
      "Reward at timestep 8.0: -51895588.0\n",
      "Reward at timestep 9.0: -54105588.0\n",
      "Reward at timestep 10.0: -55900296.0\n",
      "Reward at timestep 11.0: -57240296.0\n",
      "Reward at timestep 12.0: -58322924.0\n",
      "Reward at timestep 13.0: -59162924.0\n",
      "Reward at timestep 14.0: -75082928.0\n",
      "Reward at timestep 15.0: -75524216.0\n",
      "Reward at timestep 16.0: -75764216.0\n",
      "Reward at timestep 17.0: -75919464.0\n",
      "Reward at timestep 18.0: -76031288.0\n",
      "Reward at timestep 19.0: -76111288.0\n",
      "Reward at timestep 20.0: -76183496.0\n",
      "Reward at timestep 21.0: -92144488.0\n",
      "Reward at timestep 22.0: -92185808.0\n",
      "Reward at timestep 23.0: -92206576.0\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -7314020.0\n",
      "Reward at timestep 2.0: -8336589.5\n",
      "Reward at timestep 3.0: -8877301.0\n",
      "Reward at timestep 4.0: -9327301.0\n",
      "Reward at timestep 5.0: -9741002.0\n",
      "Reward at timestep 6.0: -10063741.0\n",
      "Reward at timestep 7.0: -10287459.0\n",
      "Reward at timestep 8.0: -10397459.0\n",
      "Reward at timestep 9.0: -10487459.0\n",
      "Reward at timestep 10.0: -10544119.0\n",
      "Reward at timestep 11.0: -10584119.0\n",
      "Reward at timestep 12.0: -10614119.0\n",
      "Reward at timestep 13.0: -10634119.0\n",
      "Reward at timestep 14.0: -10647527.0\n",
      "Reward at timestep 15.0: -10647527.0\n",
      "Reward at timestep 16.0: -10647527.0\n",
      "Reward at timestep 17.0: -10649845.0\n",
      "Reward at timestep 18.0: -10652564.0\n",
      "Reward at timestep 19.0: -10652564.0\n",
      "Reward at timestep 20.0: -10652564.0\n",
      "Reward at timestep 21.0: -10653852.0\n",
      "Reward at timestep 22.0: -10657716.0\n",
      "Reward at timestep 23.0: -10658675.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -5264020.0\n",
      "Reward at timestep 2.0: -5285858.5\n",
      "Reward at timestep 3.0: -5288200.0\n",
      "Reward at timestep 4.0: -21502764.0\n",
      "Reward at timestep 5.0: -21504070.0\n",
      "Reward at timestep 6.0: -37904072.0\n",
      "Reward at timestep 7.0: -37905388.0\n",
      "Reward at timestep 8.0: -37906632.0\n",
      "Reward at timestep 9.0: -37909356.0\n",
      "Reward at timestep 10.0: -37915772.0\n",
      "Reward at timestep 11.0: -37915772.0\n",
      "Reward at timestep 12.0: -37915772.0\n",
      "Reward at timestep 13.0: -37918068.0\n",
      "Reward at timestep 14.0: -37921932.0\n",
      "Reward at timestep 15.0: -37925280.0\n",
      "Reward at timestep 16.0: -37925280.0\n",
      "Reward at timestep 17.0: -37930532.0\n",
      "Reward at timestep 18.0: -37930532.0\n",
      "Reward at timestep 19.0: -37932944.0\n",
      "Reward at timestep 20.0: -37935004.0\n",
      "Reward at timestep 21.0: -37936224.0\n",
      "Reward at timestep 22.0: -37936224.0\n",
      "Reward at timestep 23.0: -37937312.0\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4874020.0\n",
      "Reward at timestep 2.0: -4874945.5\n",
      "Reward at timestep 3.0: -4878624.0\n",
      "Reward at timestep 4.0: -4883823.5\n",
      "Reward at timestep 5.0: -4889595.0\n",
      "Reward at timestep 6.0: -4889595.0\n",
      "Reward at timestep 7.0: -4893279.0\n",
      "Reward at timestep 8.0: -4894674.5\n",
      "Reward at timestep 9.0: -4894674.5\n",
      "Reward at timestep 10.0: -4898250.5\n",
      "Reward at timestep 11.0: -4898250.5\n",
      "Reward at timestep 12.0: -4898250.5\n",
      "Reward at timestep 13.0: -4898250.5\n",
      "Reward at timestep 14.0: -4898250.5\n",
      "Reward at timestep 15.0: -4898250.5\n",
      "Reward at timestep 16.0: -4898250.5\n",
      "Reward at timestep 17.0: -4898250.5\n",
      "Reward at timestep 18.0: -4901441.0\n",
      "Reward at timestep 19.0: -4901441.0\n",
      "Reward at timestep 20.0: -4901441.0\n",
      "Reward at timestep 21.0: -4904142.5\n",
      "Reward at timestep 22.0: -4905786.5\n",
      "Reward at timestep 23.0: -4907977.0\n",
      "Episode 7\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4844020.0\n",
      "Reward at timestep 2.0: -4844945.5\n",
      "Reward at timestep 3.0: -4848624.0\n",
      "Reward at timestep 4.0: -4853823.5\n",
      "Reward at timestep 5.0: -4859595.0\n",
      "Reward at timestep 6.0: -4859595.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 7.0: -4863279.0\n",
      "Reward at timestep 8.0: -4864674.5\n",
      "Reward at timestep 9.0: -4864674.5\n",
      "Reward at timestep 10.0: -4868250.5\n",
      "Reward at timestep 11.0: -4868250.5\n",
      "Reward at timestep 12.0: -4868250.5\n",
      "Reward at timestep 13.0: -4868250.5\n",
      "Reward at timestep 14.0: -4868250.5\n",
      "Reward at timestep 15.0: -21238250.0\n",
      "Reward at timestep 16.0: -21239576.0\n",
      "Reward at timestep 17.0: -21239576.0\n",
      "Reward at timestep 18.0: -21239576.0\n",
      "Reward at timestep 19.0: -21241982.0\n",
      "Reward at timestep 20.0: -37595808.0\n",
      "Reward at timestep 21.0: -37597036.0\n",
      "Reward at timestep 22.0: -37597036.0\n",
      "Reward at timestep 23.0: -37597036.0\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4844020.0\n",
      "Reward at timestep 2.0: -4844945.5\n",
      "Reward at timestep 3.0: -4848624.0\n",
      "Reward at timestep 4.0: -4853823.5\n",
      "Reward at timestep 5.0: -4859595.0\n",
      "Reward at timestep 6.0: -21209596.0\n",
      "Reward at timestep 7.0: -21210824.0\n",
      "Reward at timestep 8.0: -21212842.0\n",
      "Reward at timestep 9.0: -21215286.0\n",
      "Reward at timestep 10.0: -21222104.0\n",
      "Reward at timestep 11.0: -21223328.0\n",
      "Reward at timestep 12.0: -21223328.0\n",
      "Reward at timestep 13.0: -21223328.0\n",
      "Reward at timestep 14.0: -21225910.0\n",
      "Reward at timestep 15.0: -21228644.0\n",
      "Reward at timestep 16.0: -21228644.0\n",
      "Reward at timestep 17.0: -21234314.0\n",
      "Reward at timestep 18.0: -21234314.0\n",
      "Reward at timestep 19.0: -21237252.0\n",
      "Reward at timestep 20.0: -21240396.0\n",
      "Reward at timestep 21.0: -21240396.0\n",
      "Reward at timestep 22.0: -21241576.0\n",
      "Reward at timestep 23.0: -21243074.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4834020.0\n",
      "Reward at timestep 2.0: -4834945.5\n",
      "Reward at timestep 3.0: -4838624.0\n",
      "Reward at timestep 4.0: -4843823.5\n",
      "Reward at timestep 5.0: -4849595.0\n",
      "Reward at timestep 6.0: -4849595.0\n",
      "Reward at timestep 7.0: -4853279.0\n",
      "Reward at timestep 8.0: -4854674.5\n",
      "Reward at timestep 9.0: -4854674.5\n",
      "Reward at timestep 10.0: -4858250.5\n",
      "Reward at timestep 11.0: -4858250.5\n",
      "Reward at timestep 12.0: -4858250.5\n",
      "Reward at timestep 13.0: -4858250.5\n",
      "Reward at timestep 14.0: -20978250.0\n",
      "Reward at timestep 15.0: -20979508.0\n",
      "Reward at timestep 16.0: -20979508.0\n",
      "Reward at timestep 17.0: -20983684.0\n",
      "Reward at timestep 18.0: -20983684.0\n",
      "Reward at timestep 19.0: -20986044.0\n",
      "Reward at timestep 20.0: -36980124.0\n",
      "Reward at timestep 21.0: -36981372.0\n",
      "Reward at timestep 22.0: -36984312.0\n",
      "Reward at timestep 23.0: -36984312.0\n",
      "Complete\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4830000.0\n",
      "Reward at timestep 2.0: -5211943.0\n",
      "Reward at timestep 3.0: -5214499.5\n",
      "Reward at timestep 4.0: -5218251.5\n",
      "Reward at timestep 5.0: -5219516.0\n",
      "Reward at timestep 6.0: -5219516.0\n",
      "Reward at timestep 7.0: -5222423.0\n",
      "Reward at timestep 8.0: -5225670.5\n",
      "Reward at timestep 9.0: -5225670.5\n",
      "Reward at timestep 10.0: -5226949.5\n",
      "Reward at timestep 11.0: -5229066.5\n",
      "Reward at timestep 12.0: -5231722.5\n",
      "Reward at timestep 13.0: -5233330.5\n",
      "Reward at timestep 14.0: -5233330.5\n",
      "Reward at timestep 15.0: -5234544.0\n",
      "Reward at timestep 16.0: -5238228.5\n",
      "Reward at timestep 17.0: -5242480.0\n",
      "Reward at timestep 18.0: -5242480.0\n",
      "Reward at timestep 19.0: -5245283.0\n",
      "Reward at timestep 20.0: -21236256.0\n",
      "Reward at timestep 21.0: -37497556.0\n",
      "Reward at timestep 22.0: -53788908.0\n",
      "Reward at timestep 23.0: -53790180.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4590000.0\n",
      "Reward at timestep 2.0: -20571058.0\n",
      "Reward at timestep 3.0: -20572286.0\n",
      "Reward at timestep 4.0: -20574358.0\n",
      "Reward at timestep 5.0: -20577538.0\n",
      "Reward at timestep 6.0: -20577538.0\n",
      "Reward at timestep 7.0: -36718896.0\n",
      "Reward at timestep 8.0: -36720164.0\n",
      "Reward at timestep 9.0: -36724156.0\n",
      "Reward at timestep 10.0: -36727452.0\n",
      "Reward at timestep 11.0: -36730092.0\n",
      "Reward at timestep 12.0: -36731720.0\n",
      "Reward at timestep 13.0: -53162472.0\n",
      "Reward at timestep 14.0: -53164360.0\n",
      "Reward at timestep 15.0: -53164360.0\n",
      "Reward at timestep 16.0: -53164360.0\n",
      "Reward at timestep 17.0: -53169624.0\n",
      "Reward at timestep 18.0: -53169624.0\n",
      "Reward at timestep 19.0: -53169624.0\n",
      "Reward at timestep 20.0: -53171344.0\n",
      "Reward at timestep 21.0: -53173740.0\n",
      "Reward at timestep 22.0: -53175088.0\n",
      "Reward at timestep 23.0: -53176896.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4500000.0\n",
      "Reward at timestep 2.0: -4501097.0\n",
      "Reward at timestep 3.0: -4502229.5\n",
      "Reward at timestep 4.0: -4504013.0\n",
      "Reward at timestep 5.0: -4504013.0\n",
      "Reward at timestep 6.0: -4506029.5\n",
      "Reward at timestep 7.0: -4509192.5\n",
      "Reward at timestep 8.0: -4511304.0\n",
      "Reward at timestep 9.0: -4511304.0\n",
      "Reward at timestep 10.0: -4513773.0\n",
      "Reward at timestep 11.0: -4515760.0\n",
      "Reward at timestep 12.0: -4517145.0\n",
      "Reward at timestep 13.0: -4518158.5\n",
      "Reward at timestep 14.0: -4520274.0\n",
      "Reward at timestep 15.0: -4521875.5\n",
      "Reward at timestep 16.0: -4521875.5\n",
      "Reward at timestep 17.0: -4525201.5\n",
      "Reward at timestep 18.0: -4525201.5\n",
      "Reward at timestep 19.0: -4527552.0\n",
      "Reward at timestep 20.0: -4539668.0\n",
      "Reward at timestep 21.0: -4549668.0\n",
      "Reward at timestep 22.0: -4560950.0\n",
      "Reward at timestep 23.0: -4564225.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4490000.0\n",
      "Reward at timestep 2.0: -4491097.0\n",
      "Reward at timestep 3.0: -4492686.0\n",
      "Reward at timestep 4.0: -4492686.0\n",
      "Reward at timestep 5.0: -4493806.5\n",
      "Reward at timestep 6.0: -4493806.5\n",
      "Reward at timestep 7.0: -4493806.5\n",
      "Reward at timestep 8.0: -4496302.0\n",
      "Reward at timestep 9.0: -4496302.0\n",
      "Reward at timestep 10.0: -4496845.0\n",
      "Reward at timestep 11.0: -4500152.5\n",
      "Reward at timestep 12.0: -4501715.0\n",
      "Reward at timestep 13.0: -20235574.0\n",
      "Reward at timestep 14.0: -20237738.0\n",
      "Reward at timestep 15.0: -20237738.0\n",
      "Reward at timestep 16.0: -20242094.0\n",
      "Reward at timestep 17.0: -36333712.0\n",
      "Reward at timestep 18.0: -36334984.0\n",
      "Reward at timestep 19.0: -36338572.0\n",
      "Reward at timestep 20.0: -36340204.0\n",
      "Reward at timestep 21.0: -36342464.0\n",
      "Reward at timestep 22.0: -36343288.0\n",
      "Reward at timestep 23.0: -36346244.0\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4490000.0\n",
      "Reward at timestep 2.0: -4491097.0\n",
      "Reward at timestep 3.0: -4492686.0\n",
      "Reward at timestep 4.0: -4492686.0\n",
      "Reward at timestep 5.0: -4493806.5\n",
      "Reward at timestep 6.0: -4493806.5\n",
      "Reward at timestep 7.0: -4493806.5\n",
      "Reward at timestep 8.0: -4506302.0\n",
      "Reward at timestep 9.0: -4506302.0\n",
      "Reward at timestep 10.0: -4506845.0\n",
      "Reward at timestep 11.0: -4510152.5\n",
      "Reward at timestep 12.0: -4511715.0\n",
      "Reward at timestep 13.0: -4515574.0\n",
      "Reward at timestep 14.0: -4517223.5\n",
      "Reward at timestep 15.0: -20478174.0\n",
      "Reward at timestep 16.0: -20479462.0\n",
      "Reward at timestep 17.0: -20482666.0\n",
      "Reward at timestep 18.0: -20482666.0\n",
      "Reward at timestep 19.0: -20484484.0\n",
      "Reward at timestep 20.0: -20487508.0\n",
      "Reward at timestep 21.0: -20489826.0\n",
      "Reward at timestep 22.0: -20492888.0\n",
      "Reward at timestep 23.0: -20495846.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4470000.0\n",
      "Reward at timestep 2.0: -4471097.0\n",
      "Reward at timestep 3.0: -4472686.0\n",
      "Reward at timestep 4.0: -4472686.0\n",
      "Reward at timestep 5.0: -4473806.5\n",
      "Reward at timestep 6.0: -4473806.5\n",
      "Reward at timestep 7.0: -20633806.0\n",
      "Reward at timestep 8.0: -20635132.0\n",
      "Reward at timestep 9.0: -20635132.0\n",
      "Reward at timestep 10.0: -20637168.0\n",
      "Reward at timestep 11.0: -20639962.0\n",
      "Reward at timestep 12.0: -20639962.0\n",
      "Reward at timestep 13.0: -20643700.0\n",
      "Reward at timestep 14.0: -20645370.0\n",
      "Reward at timestep 15.0: -20646746.0\n",
      "Reward at timestep 16.0: -20646746.0\n",
      "Reward at timestep 17.0: -20649314.0\n",
      "Reward at timestep 18.0: -20650970.0\n",
      "Reward at timestep 19.0: -20653284.0\n",
      "Reward at timestep 20.0: -37204608.0\n",
      "Reward at timestep 21.0: -37205924.0\n",
      "Reward at timestep 22.0: -37206604.0\n",
      "Reward at timestep 23.0: -37208036.0\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4470000.0\n",
      "Reward at timestep 2.0: -4471097.0\n",
      "Reward at timestep 3.0: -4472686.0\n",
      "Reward at timestep 4.0: -4472686.0\n",
      "Reward at timestep 5.0: -4473806.5\n",
      "Reward at timestep 6.0: -4473806.5\n",
      "Reward at timestep 7.0: -4473806.5\n",
      "Reward at timestep 8.0: -4476302.0\n",
      "Reward at timestep 9.0: -4476302.0\n",
      "Reward at timestep 10.0: -4476845.0\n",
      "Reward at timestep 11.0: -4480152.5\n",
      "Reward at timestep 12.0: -4481715.0\n",
      "Reward at timestep 13.0: -4485574.0\n",
      "Reward at timestep 14.0: -4487223.5\n",
      "Reward at timestep 15.0: -4488173.5\n",
      "Reward at timestep 16.0: -4488173.5\n",
      "Reward at timestep 17.0: -4489660.5\n",
      "Reward at timestep 18.0: -4492253.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 19.0: -4494162.5\n",
      "Reward at timestep 20.0: -4496251.0\n",
      "Reward at timestep 21.0: -4498532.5\n",
      "Reward at timestep 22.0: -4500552.5\n",
      "Reward at timestep 23.0: -4503962.5\n",
      "Episode 7\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4470000.0\n",
      "Reward at timestep 2.0: -4471097.0\n",
      "Reward at timestep 3.0: -4472686.0\n",
      "Reward at timestep 4.0: -4472686.0\n",
      "Reward at timestep 5.0: -4473806.5\n",
      "Reward at timestep 6.0: -4473806.5\n",
      "Reward at timestep 7.0: -4473806.5\n",
      "Reward at timestep 8.0: -4476302.0\n",
      "Reward at timestep 9.0: -4476302.0\n",
      "Reward at timestep 10.0: -4476845.0\n",
      "Reward at timestep 11.0: -4480152.5\n",
      "Reward at timestep 12.0: -4481715.0\n",
      "Reward at timestep 13.0: -4485574.0\n",
      "Reward at timestep 14.0: -4487223.5\n",
      "Reward at timestep 15.0: -4488173.5\n",
      "Reward at timestep 16.0: -4488173.5\n",
      "Reward at timestep 17.0: -4489660.5\n",
      "Reward at timestep 18.0: -4492253.0\n",
      "Reward at timestep 19.0: -4494162.5\n",
      "Reward at timestep 20.0: -4496251.0\n",
      "Reward at timestep 21.0: -4498532.5\n",
      "Reward at timestep 22.0: -4500552.5\n",
      "Reward at timestep 23.0: -4503962.5\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4470000.0\n",
      "Reward at timestep 2.0: -20901096.0\n",
      "Reward at timestep 3.0: -20901934.0\n",
      "Reward at timestep 4.0: -20904254.0\n",
      "Reward at timestep 5.0: -20904254.0\n",
      "Reward at timestep 6.0: -20904254.0\n",
      "Reward at timestep 7.0: -20907656.0\n",
      "Reward at timestep 8.0: -37230116.0\n",
      "Reward at timestep 9.0: -37231376.0\n",
      "Reward at timestep 10.0: -37232156.0\n",
      "Reward at timestep 11.0: -37235268.0\n",
      "Reward at timestep 12.0: -37236948.0\n",
      "Reward at timestep 13.0: -37238668.0\n",
      "Reward at timestep 14.0: -37238668.0\n",
      "Reward at timestep 15.0: -37241580.0\n",
      "Reward at timestep 16.0: -37241580.0\n",
      "Reward at timestep 17.0: -53204032.0\n",
      "Reward at timestep 18.0: -53205300.0\n",
      "Reward at timestep 19.0: -53208120.0\n",
      "Reward at timestep 20.0: -53210476.0\n",
      "Reward at timestep 21.0: -53211896.0\n",
      "Reward at timestep 22.0: -53215236.0\n",
      "Reward at timestep 23.0: -53217128.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4470000.0\n",
      "Reward at timestep 2.0: -4471097.0\n",
      "Reward at timestep 3.0: -4472686.0\n",
      "Reward at timestep 4.0: -4472686.0\n",
      "Reward at timestep 5.0: -4473806.5\n",
      "Reward at timestep 6.0: -4473806.5\n",
      "Reward at timestep 7.0: -4473806.5\n",
      "Reward at timestep 8.0: -4476302.0\n",
      "Reward at timestep 9.0: -4476302.0\n",
      "Reward at timestep 10.0: -4476845.0\n",
      "Reward at timestep 11.0: -4480152.5\n",
      "Reward at timestep 12.0: -4481715.0\n",
      "Reward at timestep 13.0: -4485574.0\n",
      "Reward at timestep 14.0: -4487223.5\n",
      "Reward at timestep 15.0: -4488173.5\n",
      "Reward at timestep 16.0: -4488173.5\n",
      "Reward at timestep 17.0: -4489660.5\n",
      "Reward at timestep 18.0: -4492253.0\n",
      "Reward at timestep 19.0: -4494162.5\n",
      "Reward at timestep 20.0: -4496251.0\n",
      "Reward at timestep 21.0: -4498532.5\n",
      "Reward at timestep 22.0: -4500552.5\n",
      "Reward at timestep 23.0: -4503962.5\n",
      "Complete\n",
      "Episode 0\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4472876.0\n",
      "Reward at timestep 2.0: -4473848.5\n",
      "Reward at timestep 3.0: -4475126.0\n",
      "Reward at timestep 4.0: -4477124.5\n",
      "Reward at timestep 5.0: -4478584.5\n",
      "Reward at timestep 6.0: -4479624.0\n",
      "Reward at timestep 7.0: -4481526.0\n",
      "Reward at timestep 8.0: -4483420.5\n",
      "Reward at timestep 9.0: -4484593.5\n",
      "Reward at timestep 10.0: -4486879.5\n",
      "Reward at timestep 11.0: -4489532.0\n",
      "Reward at timestep 12.0: -4490544.5\n",
      "Reward at timestep 13.0: -4491990.0\n",
      "Reward at timestep 14.0: -4493012.5\n",
      "Reward at timestep 15.0: -4495127.5\n",
      "Reward at timestep 16.0: -4498133.0\n",
      "Reward at timestep 17.0: -4499465.0\n",
      "Reward at timestep 18.0: -4500734.5\n",
      "Reward at timestep 19.0: -4503527.5\n",
      "Reward at timestep 20.0: -4514220.0\n",
      "Reward at timestep 21.0: -4516788.0\n",
      "Reward at timestep 22.0: -20638186.0\n",
      "Reward at timestep 23.0: -20639346.0\n",
      "Episode 1\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4502876.0\n",
      "Reward at timestep 2.0: -4504384.5\n",
      "Reward at timestep 3.0: -4506286.5\n",
      "Reward at timestep 4.0: -4508917.0\n",
      "Reward at timestep 5.0: -4512027.5\n",
      "Reward at timestep 6.0: -4513414.0\n",
      "Reward at timestep 7.0: -4515679.5\n",
      "Reward at timestep 8.0: -4517607.0\n",
      "Reward at timestep 9.0: -4518559.5\n",
      "Reward at timestep 10.0: -4521136.5\n",
      "Reward at timestep 11.0: -4523419.5\n",
      "Reward at timestep 12.0: -4525834.5\n",
      "Reward at timestep 13.0: -4528992.0\n",
      "Reward at timestep 14.0: -4528992.0\n",
      "Reward at timestep 15.0: -4530285.0\n",
      "Reward at timestep 16.0: -4532949.0\n",
      "Reward at timestep 17.0: -4534232.5\n",
      "Reward at timestep 18.0: -20286432.0\n",
      "Reward at timestep 19.0: -20287750.0\n",
      "Reward at timestep 20.0: -36440120.0\n",
      "Reward at timestep 21.0: -36441348.0\n",
      "Reward at timestep 22.0: -36441348.0\n",
      "Reward at timestep 23.0: -36444296.0\n",
      "Episode 2\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -16162876.0\n",
      "Reward at timestep 2.0: -16164147.0\n",
      "Reward at timestep 3.0: -16165613.0\n",
      "Reward at timestep 4.0: -16168416.0\n",
      "Reward at timestep 5.0: -16171555.0\n",
      "Reward at timestep 6.0: -16174750.0\n",
      "Reward at timestep 7.0: -16176203.0\n",
      "Reward at timestep 8.0: -16177874.0\n",
      "Reward at timestep 9.0: -16179552.0\n",
      "Reward at timestep 10.0: -16181676.0\n",
      "Reward at timestep 11.0: -16183798.0\n",
      "Reward at timestep 12.0: -16184979.0\n",
      "Reward at timestep 13.0: -16187399.0\n",
      "Reward at timestep 14.0: -16187399.0\n",
      "Reward at timestep 15.0: -16190208.0\n",
      "Reward at timestep 16.0: -16192734.0\n",
      "Reward at timestep 17.0: -16192734.0\n",
      "Reward at timestep 18.0: -16193895.0\n",
      "Reward at timestep 19.0: -16195988.0\n",
      "Reward at timestep 20.0: -16207735.0\n",
      "Reward at timestep 21.0: -16219025.0\n",
      "Reward at timestep 22.0: -16229025.0\n",
      "Reward at timestep 23.0: -16231593.0\n",
      "Episode 3\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4502876.0\n",
      "Reward at timestep 2.0: -4504271.0\n",
      "Reward at timestep 3.0: -4506272.0\n",
      "Reward at timestep 4.0: -4508664.0\n",
      "Reward at timestep 5.0: -4510274.5\n",
      "Reward at timestep 6.0: -4511617.0\n",
      "Reward at timestep 7.0: -4513060.0\n",
      "Reward at timestep 8.0: -4514106.5\n",
      "Reward at timestep 9.0: -4517043.5\n",
      "Reward at timestep 10.0: -4518223.0\n",
      "Reward at timestep 11.0: -4520629.0\n",
      "Reward at timestep 12.0: -4521933.0\n",
      "Reward at timestep 13.0: -4525383.5\n",
      "Reward at timestep 14.0: -4526897.5\n",
      "Reward at timestep 15.0: -4529588.5\n",
      "Reward at timestep 16.0: -4531451.5\n",
      "Reward at timestep 17.0: -4532887.0\n",
      "Reward at timestep 18.0: -4535197.0\n",
      "Reward at timestep 19.0: -4536893.0\n",
      "Reward at timestep 20.0: -4538701.5\n",
      "Reward at timestep 21.0: -4541844.0\n",
      "Reward at timestep 22.0: -4543726.5\n",
      "Reward at timestep 23.0: -4545338.5\n",
      "Episode 4\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -4499615.5\n",
      "Reward at timestep 6.0: -4501275.5\n",
      "Reward at timestep 7.0: -4503273.0\n",
      "Reward at timestep 8.0: -4504113.5\n",
      "Reward at timestep 9.0: -4506143.5\n",
      "Reward at timestep 10.0: -4507644.0\n",
      "Reward at timestep 11.0: -4510688.5\n",
      "Reward at timestep 12.0: -4513374.0\n",
      "Reward at timestep 13.0: -4515204.0\n",
      "Reward at timestep 14.0: -4517198.0\n",
      "Reward at timestep 15.0: -4517198.0\n",
      "Reward at timestep 16.0: -4521687.5\n",
      "Reward at timestep 17.0: -4522130.0\n",
      "Reward at timestep 18.0: -4522691.5\n",
      "Reward at timestep 19.0: -4523404.5\n",
      "Reward at timestep 20.0: -4526696.5\n",
      "Reward at timestep 21.0: -4527391.0\n",
      "Reward at timestep 22.0: -4528439.5\n",
      "Reward at timestep 23.0: -20780492.0\n",
      "Episode 5\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -4499615.5\n",
      "Reward at timestep 6.0: -4501275.5\n",
      "Reward at timestep 7.0: -4503273.0\n",
      "Reward at timestep 8.0: -4504113.5\n",
      "Reward at timestep 9.0: -4506143.5\n",
      "Reward at timestep 10.0: -4507644.0\n",
      "Reward at timestep 11.0: -4510688.5\n",
      "Reward at timestep 12.0: -4513374.0\n",
      "Reward at timestep 13.0: -4515204.0\n",
      "Reward at timestep 14.0: -4517198.0\n",
      "Reward at timestep 15.0: -4517198.0\n",
      "Reward at timestep 16.0: -4521687.5\n",
      "Reward at timestep 17.0: -4522130.0\n",
      "Reward at timestep 18.0: -4522691.5\n",
      "Reward at timestep 19.0: -4523404.5\n",
      "Reward at timestep 20.0: -4526696.5\n",
      "Reward at timestep 21.0: -4527391.0\n",
      "Reward at timestep 22.0: -4528439.5\n",
      "Reward at timestep 23.0: -4530491.5\n",
      "Episode 6\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -4499615.5\n",
      "Reward at timestep 6.0: -4501275.5\n",
      "Reward at timestep 7.0: -4503273.0\n",
      "Reward at timestep 8.0: -4504113.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward at timestep 9.0: -20776144.0\n",
      "Reward at timestep 10.0: -20777404.0\n",
      "Reward at timestep 11.0: -20778594.0\n",
      "Reward at timestep 12.0: -20779034.0\n",
      "Reward at timestep 13.0: -20783452.0\n",
      "Reward at timestep 14.0: -20785220.0\n",
      "Reward at timestep 15.0: -20788654.0\n",
      "Reward at timestep 16.0: -20791238.0\n",
      "Reward at timestep 17.0: -20792492.0\n",
      "Reward at timestep 18.0: -20794114.0\n",
      "Reward at timestep 19.0: -20795788.0\n",
      "Reward at timestep 20.0: -20797790.0\n",
      "Reward at timestep 21.0: -20799858.0\n",
      "Reward at timestep 22.0: -20801208.0\n",
      "Reward at timestep 23.0: -20804170.0\n",
      "Episode 7\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -20839616.0\n",
      "Reward at timestep 6.0: -20841204.0\n",
      "Reward at timestep 7.0: -20842104.0\n",
      "Reward at timestep 8.0: -20843336.0\n",
      "Reward at timestep 9.0: -20845596.0\n",
      "Reward at timestep 10.0: -20846586.0\n",
      "Reward at timestep 11.0: -20848746.0\n",
      "Reward at timestep 12.0: -20849662.0\n",
      "Reward at timestep 13.0: -20852814.0\n",
      "Reward at timestep 14.0: -20853772.0\n",
      "Reward at timestep 15.0: -37225048.0\n",
      "Reward at timestep 16.0: -37226580.0\n",
      "Reward at timestep 17.0: -37230344.0\n",
      "Reward at timestep 18.0: -37231768.0\n",
      "Reward at timestep 19.0: -37233780.0\n",
      "Reward at timestep 20.0: -37235148.0\n",
      "Reward at timestep 21.0: -37237208.0\n",
      "Reward at timestep 22.0: -37238876.0\n",
      "Reward at timestep 23.0: -37241356.0\n",
      "Episode 8\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -4499615.5\n",
      "Reward at timestep 6.0: -4501275.5\n",
      "Reward at timestep 7.0: -4503273.0\n",
      "Reward at timestep 8.0: -4504113.5\n",
      "Reward at timestep 9.0: -4506143.5\n",
      "Reward at timestep 10.0: -4507644.0\n",
      "Reward at timestep 11.0: -4510688.5\n",
      "Reward at timestep 12.0: -4513374.0\n",
      "Reward at timestep 13.0: -4515204.0\n",
      "Reward at timestep 14.0: -4517198.0\n",
      "Reward at timestep 15.0: -4517198.0\n",
      "Reward at timestep 16.0: -4521687.5\n",
      "Reward at timestep 17.0: -20692130.0\n",
      "Reward at timestep 18.0: -20693432.0\n",
      "Reward at timestep 19.0: -20695536.0\n",
      "Reward at timestep 20.0: -20697216.0\n",
      "Reward at timestep 21.0: -20699960.0\n",
      "Reward at timestep 22.0: -20701218.0\n",
      "Reward at timestep 23.0: -20704194.0\n",
      "Episode 9\n",
      " Retrying in 1 seconds\n",
      "Reward at timestep 1.0: -4492876.0\n",
      "Reward at timestep 2.0: -4494059.0\n",
      "Reward at timestep 3.0: -4495737.0\n",
      "Reward at timestep 4.0: -4498203.5\n",
      "Reward at timestep 5.0: -4499615.5\n",
      "Reward at timestep 6.0: -4501275.5\n",
      "Reward at timestep 7.0: -4503273.0\n",
      "Reward at timestep 8.0: -21014112.0\n",
      "Reward at timestep 9.0: -21015370.0\n",
      "Reward at timestep 10.0: -21017568.0\n",
      "Reward at timestep 11.0: -21020036.0\n",
      "Reward at timestep 12.0: -21020036.0\n",
      "Reward at timestep 13.0: -21022778.0\n",
      "Reward at timestep 14.0: -21024764.0\n",
      "Reward at timestep 15.0: -21027080.0\n",
      "Reward at timestep 16.0: -21027818.0\n",
      "Reward at timestep 17.0: -21029334.0\n",
      "Reward at timestep 18.0: -21031794.0\n",
      "Reward at timestep 19.0: -21033794.0\n",
      "Reward at timestep 20.0: -21036678.0\n",
      "Reward at timestep 21.0: -21037728.0\n",
      "Reward at timestep 22.0: -21039242.0\n",
      "Reward at timestep 23.0: -21041312.0\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "today = str(datetime.datetime.today())[:-7]\n",
    "simconfig = 0\n",
    "\n",
    "for layers in [2,3]:\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "        \n",
    "        if layers == 2:\n",
    "            policy_net = DQN(n_actions, fc_2=True, fc_3=False).to(device)\n",
    "            target_net = DQN(n_actions, fc_2=True, fc_3=False).to(device)\n",
    "        else:\n",
    "            policy_net = DQN(n_actions, fc_2=True, fc_3=True).to(device)\n",
    "            target_net = DQN(n_actions, fc_2=True, fc_3=True).to(device)\n",
    "            \n",
    "        policy_net = nn.DataParallel(policy_net)\n",
    "        target_net = nn.DataParallel(target_net)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "\n",
    "    else:\n",
    "        print('Using 1 GPU')\n",
    "        if layers == 2:\n",
    "            policy_net = DQN(n_actions, fc_2=True, fc_3=False).to(device)\n",
    "            target_net = DQN(n_actions, fc_2=True, fc_3=False).to(device)\n",
    "        else:\n",
    "            policy_net = DQN(n_actions, fc_2=True, fc_3=True).to(device)\n",
    "            target_net = DQN(n_actions, fc_2=True, fc_3=True).to(device)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "    \n",
    "    optimizer = optim.Adam(policy_net.parameters())\n",
    "    memory = ReplayMemory(10000)\n",
    "    for i in [2,3]:\n",
    "        run_experiments(3000, today, 'km2_centro_test_day_scenario_{}_layer_{}_date_{}'.format(i, layers, today), i, layers)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "9aaa026504964800b82f3273feb2fb8a",
   "lastKernelId": "3751ebc7-a860-4980-a221-ac6c96e67ab6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
