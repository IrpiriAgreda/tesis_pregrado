{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "    import traci\n",
    "else:\n",
    "    sys.exit(\"please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "from model_classes import ActorCriticNetwork, Agent, DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important constants and state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = 5981\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dict = {\n",
    "    'dqn_base': {\n",
    "        'weight_path_1_layer': './resultados_centro_1mlp/escenario0/1_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_centro_1mlp/escenario0/2_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_centro_1mlp/escenario0/3_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario/osm.sumocfg\",\n",
    "        'plot_name': 'dqn_scenario_0'\n",
    "    },\n",
    "    'dqn_case_2x': {\n",
    "        'weight_path_1_layer': './resultados_centro_1mlp/escenario1/1_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_centro_1mlp/escenario1/2_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_centro_1mlp/escenario1/3_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario_2/osm.sumocfg\",\n",
    "        'plot_name': 'dqn_scenario_2',\n",
    "    },\n",
    "    'dqn_case_4x': {\n",
    "        'weight_path_1_layer': './resultados_centro_1mlp/escenario2/1_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_centro_1mlp/escenario2/2_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_centro_1mlp/escenario2/3_layer/policy_net_weights_experiment_ep_2999.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario_3/osm.sumocfg\",\n",
    "        'plot_name': 'dqn_scenario_3'\n",
    "    },\n",
    "    'pg_base': {\n",
    "        'weight_path_1_layer': './resultados_pg/escenario0/1_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_pg/escenario0/2_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_pg/escenario0/3_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario/osm.sumocfg\",\n",
    "        'plot_name': 'scenario_0_pg'\n",
    "    },\n",
    "    'pg_2x': {\n",
    "        'weight_path_1_layer': './resultados_pg/escenario1/1_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_pg/escenario1/2_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_pg/escenario1/3_layer/ac_weights_experiment_ep_1293.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario_2/osm.sumocfg\",\n",
    "        'plot_name': 'scenario_1_pg'\n",
    "    },\n",
    "    'pg_4x': {\n",
    "        'weight_path_1_layer': './resultados_pg/escenario2/1_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_2_layer': './resultados_pg/escenario2/2_layer/ac_weights_experiment_ep_2999.pt',\n",
    "        'weight_path_3_layer': './resultados_pg/escenario2/3_layer/ac_weights_experiment_ep_2192.pt',\n",
    "        'config': \"../sumo_simulation/sim_config/km2_centro/scenario_3/osm.sumocfg\",\n",
    "        'plot_name': 'scenario_2_pg'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dqn_sd(state_dict, num_layers):\n",
    "    state_dict[\"mlp1.weight\"] = state_dict['module.mlp1.weight']\n",
    "    state_dict[\"mlp1.bias\"] = state_dict['module.mlp1.bias']\n",
    "    state_dict[\"head.weight\"] = state_dict['module.head.weight']\n",
    "    state_dict[\"head.bias\"] = state_dict['module.head.bias']\n",
    "    \n",
    "    del state_dict['module.mlp1.weight'], state_dict['module.mlp1.bias'], state_dict['module.head.weight'], state_dict['module.head.bias']\n",
    "    \n",
    "    if num_layers == '1':\n",
    "        policy_net = DQN(n_actions, False, False).to(device)\n",
    "        \n",
    "    elif num_layers == '2':\n",
    "        policy_net = DQN(n_actions, True, False).to(device)\n",
    "        state_dict[\"mlp2.weight\"] = state_dict['module.mlp2.weight']\n",
    "        state_dict[\"mlp2.bias\"] = state_dict['module.mlp2.bias']\n",
    "        \n",
    "        del state_dict['module.mlp2.weight'], state_dict['module.mlp2.bias']\n",
    "        \n",
    "    else:\n",
    "        policy_net = DQN(n_actions, True, True).to(device)\n",
    "        state_dict[\"mlp2.weight\"] = state_dict['module.mlp2.weight']\n",
    "        state_dict[\"mlp2.bias\"] = state_dict['module.mlp2.bias']\n",
    "        state_dict[\"mlp3.weight\"] = state_dict['module.mlp3.weight']\n",
    "        state_dict[\"mlp3.bias\"] = state_dict['module.mlp3.bias']\n",
    "        \n",
    "        del state_dict['module.mlp2.weight'], state_dict['module.mlp2.bias'], state_dict['module.mlp3.weight'], state_dict['module.mlp3.bias']\n",
    "    \n",
    "\n",
    "    policy_net.load_state_dict(state_dict)\n",
    "\n",
    "    policy_net.eval()\n",
    "    \n",
    "    return policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pg_sd(state_dict, num_layers):\n",
    "    if num_layers == '1':\n",
    "        agent = Agent(alpha=0.001, input_dims=[6], gamma=0.001,\n",
    "                  n_actions=n_actions, layer2_size=False, layer3_size=False)\n",
    "   \n",
    "    elif num_layers == '2':\n",
    "        agent = Agent(alpha=0.001, input_dims=[6], gamma=0.001,\n",
    "                  n_actions=n_actions, layer3_size=False)\n",
    "    else:\n",
    "        agent = Agent(alpha=0.001, input_dims=[6], gamma=0.001,\n",
    "                  n_actions=n_actions)\n",
    "\n",
    "    agent.actor_critic.load_state_dict(state_dict)\n",
    "\n",
    "    agent.actor_critic.eval()\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main agent loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_simulation(key, weight_path, sumoCmd):\n",
    "    \n",
    "    num_layers = re.findall('\\d', weight_path)\n",
    "    \n",
    "    if 'dqn' in key:\n",
    "        num_layers = num_layers[2]\n",
    "    else:\n",
    "        num_layers = num_layers[1]\n",
    "    \n",
    "    state_dict = torch.load(weight_path)\n",
    "    \n",
    "    if 'dqn' in key:\n",
    "        agent_kind = 'dqn'\n",
    "        agent = load_dqn_sd(state_dict, num_layers)\n",
    "    else:\n",
    "        agent_kind = 'pg'\n",
    "        agent = load_pg_sd(state_dict, num_layers)\n",
    "\n",
    "    traci.start(sumoCmd)\n",
    "\n",
    "    action_dict = cPickle.load(open('../sumo_simulation/input/action_to_zone_km2_lince.pkl', 'rb'))\n",
    "    state = torch.zeros([1,6], device=device)\n",
    "    traci_ep = 0\n",
    "    lane_id_list = traci.lane.getIDList()\n",
    "\n",
    "    states_agent = []\n",
    "    states_agent_mean = []\n",
    "    truck_emissions_agent = []\n",
    "\n",
    "    for e in range(86400):\n",
    "\n",
    "        if traci_ep % 3600 == 0 and traci_ep != 0:\n",
    "\n",
    "            #Start agent interaction\n",
    "            \n",
    "            if agent_kind == 'dqn':\n",
    "                action = agent(state)\n",
    "            else:\n",
    "                action = agent.choose_action(state)\n",
    "\n",
    "            #Apply regulation and run steps\n",
    "            reg_action = action > 0\n",
    "\n",
    "            #print(reg_action.view(-1))\n",
    "\n",
    "            for index, lane_id in enumerate(reg_action.view(-1)):\n",
    "                        #for lane_id in lane_indices:\n",
    "                if lane_id.item() == 1:\n",
    "                    if action_dict[index] is not None:\n",
    "                        traci.lane.setDisallowed(action_dict[index], ['truck'])\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    if action_dict[index] is not None:\n",
    "                        traci.lane.setAllowed(action_dict[index], ['truck'])\n",
    "                    else:\n",
    "                        pass    \n",
    "\n",
    "            vehicle_id_list = traci.vehicle.getIDList()\n",
    "            \n",
    "            vehicle_types = [traci.vehicle.getTypeID(v_id) for v_id in vehicle_id_list]\n",
    "            vehicle_co2 = [traci.vehicle.getCO2Emission(v_id) for i, v_id in enumerate(vehicle_id_list) \n",
    "                                      if 'truck' in vehicle_types[i]]\n",
    "\n",
    "            try:\n",
    "                truck_emissions_agent.append(sum(vehicle_co2)/len(vehicle_co2))\n",
    "            except:\n",
    "                truck_emissions_agent.append(0)\n",
    "\n",
    "            #Get simulation values\n",
    "            co2 = [traci.lane.getCO2Emission(edge_id) for edge_id in lane_id_list]\n",
    "            co = [traci.lane.getCOEmission(edge_id) for edge_id in lane_id_list]\n",
    "            nox = [traci.lane.getNOxEmission(edge_id) for edge_id in lane_id_list]\n",
    "            pmx = [traci.lane.getPMxEmission(edge_id) for edge_id in lane_id_list]\n",
    "            noise = [traci.lane.getNoiseEmission(edge_id) for edge_id in lane_id_list]\n",
    "            fuel = [traci.lane.getFuelConsumption(edge_id) for edge_id in lane_id_list]\n",
    "\n",
    "            sim_results = np.array([co2, co, pmx, nox, noise, fuel])\n",
    "\n",
    "            next_state = np.transpose(sim_results).mean(axis=0)\n",
    "            \n",
    "            states_agent.append(np.transpose(sim_results).sum(axis=0))\n",
    "            states_agent_mean.append(next_state)\n",
    "\n",
    "            next_state = torch.from_numpy(next_state).to(device).float()\n",
    "\n",
    "            state += next_state\n",
    "\n",
    "        traci.simulationStep()\n",
    "        traci_ep += 1\n",
    "    traci.close(False)\n",
    "    \n",
    "    if agent_kind == 'dqn':\n",
    "        values = [agent(torch.from_numpy(state).float().to(device).view(-1,6)) \n",
    "                  for state in states_agent_mean]\n",
    "    else:\n",
    "        values = [agent.choose_action(torch.from_numpy(state).float().to(device).view(-1,6)) \n",
    "                  for state in states_agent_mean]\n",
    "    \n",
    "    \n",
    "    #values = torch.cat(values).view(-1).detach().cpu().numpy()\n",
    "    \n",
    "    return states_agent, truck_emissions_agent, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Dictionary to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'{}_{}_layers'.format(algorithm, layer):'' \n",
    "               for algorithm in experiment_dict.keys() for layer in range(1,4)}\n",
    "\n",
    "for key in result_dict.keys():\n",
    "    result_dict[key] = {k: '' for k in ['cauchy', 'chi_squared', 'gaussian']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dqn_base weight_path_1_layer sc0\n",
      " Retrying in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "for key in experiment_dict.keys():\n",
    "    for path in experiment_dict[key]:\n",
    "        if 'weight' in path:\n",
    "            for test in ['sc0', 'sc1', 'sc2']:\n",
    "                sumoCmd = ['/usr/bin/sumo/bin/sumo','-c',\n",
    "             '/home/andres/Documents/tesis_pregrado/sumo_simulation/sim_config/km2_lince/geo_test/{}/osm.sumocfg'.format(test),\n",
    "             '-e', '86400']\n",
    "                print(key, path, test)\n",
    "                result_dict['_'.join([key,path.split('_')[2], 'layers'])][test] = run_agent_simulation(key, experiment_dict[key][path], sumoCmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in ['sc0', 'sc1', 'sc2']:\n",
    "    for key in result_dict.keys():\n",
    "        print(key, test)\n",
    "        np.save('arrays_lince/{}_{}.npy'.format(key,test), np.array(result_dict[key][test][0]).sum(axis=0))\n",
    "        print(list(np.array(result_dict[key][test][0]).sum(axis=0)))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "398b6112caca451980e50fbcf90dd3ec",
   "lastKernelId": "30f025f8-1bd3-457b-be05-6d3077ce6eb0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
